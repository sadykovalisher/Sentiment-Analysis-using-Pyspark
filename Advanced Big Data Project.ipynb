{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6f346c-b29b-4693-b281-1ad2b581de45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.64.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffffb30e90f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e63143-1a89-44f6-9e0f-d7a9e3491d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.64.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91374c4d-43f8-4215-9cc5-1e4575943566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9e650d-57d1-4c25-a0d3-600526de4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------------------------+--------------+-------------------------+--------------+----------------------+----------+-------------------+-------------+--------------------+-----------+---------------+--------------+--------------------+\n",
      "|   tweet_id|airline_sentiment|airline_sentiment_confidence|negativereason|negativereason_confidence|       airline|airline_sentiment_gold|      name|negativereason_gold|retweet_count|                text|tweet_coord|  tweet_created|tweet_location|       user_timezone|\n",
      "+-----------+-----------------+----------------------------+--------------+-------------------------+--------------+----------------------+----------+-------------------+-------------+--------------------+-----------+---------------+--------------+--------------------+\n",
      "|5.70306E+17|          neutral|                           1|          null|                     null|Virgin America|                  null|   cairdin|               null|            0|@VirginAmerica Wh...|       null|2/24/2015 11:35|          null|Eastern Time (US ...|\n",
      "|5.70301E+17|         positive|                      0.3486|          null|                        0|Virgin America|                  null|  jnardino|               null|            0|@VirginAmerica pl...|       null|2/24/2015 11:15|          null|Pacific Time (US ...|\n",
      "|5.70301E+17|          neutral|                      0.6837|          null|                     null|Virgin America|                  null|yvonnalynn|               null|            0|@VirginAmerica I ...|       null|2/24/2015 11:15|     Lets Play|Central Time (US ...|\n",
      "+-----------+-----------------+----------------------------+--------------+-------------------------+--------------+----------------------+----------+-------------------+-------------+--------------------+-----------+---------------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_csv=spark.read.csv(\"file:///home/alish/pyspark codes/Twitter Data.csv\", inferSchema=True, header=True)\n",
    "tweet_csv.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231c3392-acf0-4c1e-b01c-8b28f3157abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------+--------+\n",
      "|text                                                                                                                              |label   |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------+--------+\n",
      "|@VirginAmerica What @dhepburn said.                                                                                               |neutral |\n",
      "|@VirginAmerica plus you've added commercials to the experience... tacky.                                                          |positive|\n",
      "|@VirginAmerica I didn't today... Must mean I need to take another trip!                                                           |neutral |\n",
      "|\"@VirginAmerica it's really aggressive to blast obnoxious \"\"entertainment\"\" in your guests' faces &amp; they have little recourse\"|negative|\n",
      "|@VirginAmerica and it's a really big bad thing about it                                                                           |negative|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=tweet_csv.select(\n",
    "    \"text\",col(\"airline_sentiment\").cast(\"String\").alias(\"label\"))\n",
    "data.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a241542b-86aa-4b3c-9fea-c25bcb6588d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------------+\n",
      "|                text|   label|encoded_label|\n",
      "+--------------------+--------+-------------+\n",
      "|@VirginAmerica Wh...| neutral|            1|\n",
      "|@VirginAmerica pl...|positive|            2|\n",
      "|@VirginAmerica I ...| neutral|            1|\n",
      "|\"@VirginAmerica i...|negative|            0|\n",
      "|@VirginAmerica an...|negative|            0|\n",
      "|@VirginAmerica se...|negative|            0|\n",
      "|                null|    null|         null|\n",
      "|@VirginAmerica ye...|positive|            2|\n",
      "|@VirginAmerica Re...| neutral|            1|\n",
      "|@virginamerica We...|positive|            2|\n",
      "|@VirginAmerica it...|positive|            2|\n",
      "|@VirginAmerica di...| neutral|            1|\n",
      "|@VirginAmerica I ...|positive|            2|\n",
      "|@VirginAmerica Th...|positive|            2|\n",
      "|@VirginAmerica @v...|positive|            2|\n",
      "|@VirginAmerica Th...|positive|            2|\n",
      "|@VirginAmerica SF...|negative|            0|\n",
      "|@VirginAmerica So...|positive|            2|\n",
      "|@VirginAmerica  I...|negative|            0|\n",
      "|I ❤️ flying @Virg...|positive|            2|\n",
      "+--------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {\"neutral\": 1, \"positive\": 2, \"negative\": 0}\n",
    "\n",
    "data = data.withColumn(\"encoded_label\", \n",
    "                          when(col(\"label\") == \"neutral\", label_mapping[\"neutral\"])\n",
    "                          .when(col(\"label\") == \"positive\", label_mapping[\"positive\"])\n",
    "                          .when(col(\"label\") == \"negative\", label_mapping[\"negative\"]))\n",
    "\n",
    "# Show the result\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958d07cc-489f-467b-9158-3e955c310279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data=data.drop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6e9bdf-1b02-4e71-9eae-b08474584b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|                text|encoded_label|\n",
      "+--------------------+-------------+\n",
      "|@VirginAmerica Wh...|            1|\n",
      "|@VirginAmerica pl...|            2|\n",
      "|@VirginAmerica I ...|            1|\n",
      "|\"@VirginAmerica i...|            0|\n",
      "|@VirginAmerica an...|            0|\n",
      "|@VirginAmerica se...|            0|\n",
      "|@VirginAmerica ye...|            2|\n",
      "|@VirginAmerica Re...|            1|\n",
      "|@virginamerica We...|            2|\n",
      "|@VirginAmerica it...|            2|\n",
      "|@VirginAmerica di...|            1|\n",
      "|@VirginAmerica I ...|            2|\n",
      "|@VirginAmerica Th...|            2|\n",
      "|@VirginAmerica @v...|            2|\n",
      "|@VirginAmerica Th...|            2|\n",
      "|@VirginAmerica SF...|            0|\n",
      "|@VirginAmerica So...|            2|\n",
      "|@VirginAmerica  I...|            0|\n",
      "|I ❤️ flying @Virg...|            2|\n",
      "|@VirginAmerica yo...|            2|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55876b39-7539-44b2-9672-f8e2f4583429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train : 10240\n",
      "Total test : 4392\n"
     ]
    }
   ],
   "source": [
    "#Split training and Testing\n",
    "split_data=data.randomSplit([0.7,0.3])\n",
    "train=split_data[0]\n",
    "\n",
    "#label in test renamed to true label\n",
    "test=split_data[1].withColumnRenamed(\"encoded_label\",\"true_label\")\n",
    "train_rows=train.count()\n",
    "test_rows=test.count()\n",
    "\n",
    "print(\"Total train :\",train_rows)\n",
    "print(\"Total test :\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e893a769-2219-4eff-9231-2e36f44f1ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+\n",
      "|                text|encoded_label|              tokens|\n",
      "+--------------------+-------------+--------------------+\n",
      "|\"\"\"LOL you guys a...|            2|[\"\"\"lol, you, guy...|\n",
      "|\".@AmericanAir @U...|            0|[\".@americanair, ...|\n",
      "|\".@united You may...|            0|[\".@united, you, ...|\n",
      "|\"@AmericanAir  so...|            0|[\"@americanair, ,...|\n",
      "|\"@AmericanAir \"\"A...|            2|[\"@americanair, \"...|\n",
      "+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "tokenizedTrain = tokenizer.transform(train)\n",
    "tokenizedTrain.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35c50e28-f1bd-4e7f-8f8f-201e36670163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+\n",
      "|                text|encoded_label|              tokens|     MeaningfulWords|\n",
      "+--------------------+-------------+--------------------+--------------------+\n",
      "|\"\"\"LOL you guys a...|            2|[\"\"\"lol, you, guy...|[\"\"\"lol, guys, it...|\n",
      "|\".@AmericanAir @U...|            0|[\".@americanair, ...|[\".@americanair, ...|\n",
      "|\".@united You may...|            0|[\".@united, you, ...|[\".@united, may, ...|\n",
      "|\"@AmericanAir  so...|            0|[\"@americanair, ,...|[\"@americanair, ,...|\n",
      "|\"@AmericanAir \"\"A...|            2|[\"@americanair, \"...|[\"@americanair, \"...|\n",
      "+--------------------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "SwRemovedTrain.show( n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da09cad-514f-4331-9ec3-406884ce7cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+\n",
      "|encoded_label|     MeaningfulWords|            features|\n",
      "+-------------+--------------------+--------------------+\n",
      "|            2|[\"\"\"lol, guys, it...|(262144,[2040,274...|\n",
      "|            0|[\".@americanair, ...|(262144,[767,4806...|\n",
      "|            0|[\".@united, may, ...|(262144,[467,3251...|\n",
      "+-------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericTrain = hashTF.transform(SwRemovedTrain).select(\n",
    "    'encoded_label', 'MeaningfulWords', 'features')\n",
    "numericTrain.show(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da1e69b7-ec2c-44d8-8897-d1aab29dcd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 15:12:35,348 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2023-12-11 15:12:35,349 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Training Model\n",
    "lr = LogisticRegression(labelCol=\"encoded_label\", featuresCol=\"features\",maxIter=20, regParam=0.01)\n",
    "model = lr.fit(numericTrain)\n",
    "print (\"Training Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b730dcf-16eb-4531-8de5-57a0f54ca680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|                text|true_label|              tokens|     MeaningfulWords|            features|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|\".@JetBlue ooooka...|         0|[\".@jetblue, oooo...|[\".@jetblue, oooo...|(262144,[1512,138...|\n",
      "|\".@united It's wo...|         0|[\".@united, it's,...|[\".@united, worth...|(262144,[41407,51...|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare Testing data\n",
    "tokenizedTest = tokenizer.transform(test)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest)\n",
    "numericTest.show( n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "821a4f7d-007d-4e8e-aa51-c6522e490c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- true_label: integer (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- MeaningfulWords: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "raw_prediction = model.transform(numericTest)\n",
    "raw_prediction.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc397483-dd7e-4cf8-89e7-0d40abeaca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+\n",
      "|     MeaningfulWords|prediction|true_label|\n",
      "+--------------------+----------+----------+\n",
      "|[\".@jetblue, oooo...|       1.0|         0|\n",
      "|[\".@united, worth...|       0.0|         0|\n",
      "|[\"@americanair, ,...|       0.0|         0|\n",
      "|[\"@americanair, -...|       0.0|         0|\n",
      "|[\"@americanair, @...|       0.0|         0|\n",
      "|[\"@americanair, a...|       0.0|         0|\n",
      "|[\"@americanair, a...|       0.0|         0|\n",
      "|[\"@americanair, a...|       0.0|         0|\n",
      "|[\"@americanair, d...|       0.0|         0|\n",
      "|[\"@americanair, h...|       0.0|         1|\n",
      "|[\"@americanair, \"...|       0.0|         0|\n",
      "|[\"@americanair, u...|       0.0|         0|\n",
      "|[\"@americanair, o...|       0.0|         0|\n",
      "|[\"@americanair, l...|       0.0|         0|\n",
      "|[\"@americanair, t...|       0.0|         0|\n",
      "|[\"@americanair, h...|       0.0|         0|\n",
      "|[\"@americanair, l...|       0.0|         0|\n",
      "|[\"@americanair, e...|       0.0|         0|\n",
      "|[\"@americanair, f...|       0.0|         0|\n",
      "|[\"@americanair, h...|       0.0|         0|\n",
      "+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Final_prediction = raw_prediction.select(\"MeaningfulWords\", \"prediction\", \"true_label\")\n",
    "Final_prediction.show(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "701bc72e-39d5-4730-aa5c-9551415ededc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is: 73.86156648451731 %\n"
     ]
    }
   ],
   "source": [
    "Total_True=Final_prediction.filter(Final_prediction['prediction']==Final_prediction['true_label']).count()\n",
    "Alldata=Final_prediction.count()\n",
    "Accuracy=Total_True/Alldata\n",
    "print(\"Accuracy Score is:\", Accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54de6607-118b-4c2b-a613-a6e9658c858a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|true_label|prediction|count|\n",
      "+----------+----------+-----+\n",
      "|         0|       2.0|   88|\n",
      "|         0|       1.0|  270|\n",
      "|         0|       0.0| 2426|\n",
      "|         1|       0.0|  393|\n",
      "|         1|       1.0|  419|\n",
      "|         1|       2.0|  101|\n",
      "|         2|       1.0|   96|\n",
      "|         2|       2.0|  399|\n",
      "|         2|       0.0|  200|\n",
      "+----------+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "confusion_matrix = Final_prediction.groupBy(\"true_label\", \"prediction\").count()\n",
    "confusion_matrix.orderBy(col(\"true_label\").asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a574092-55b3-4712-bd58-b21dabdd28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real-time prediction:\n",
    "input_sentence = \"I hate this movie\"\n",
    "\n",
    "# Create a DataFrame with a single column named 'text'\n",
    "data = [(0, input_sentence)]\n",
    "\n",
    "df = spark.createDataFrame(data, [\"id\", \"text\"])\n",
    "\n",
    "tokenizedTest = tokenizer.transform(df)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest)\n",
    "raw_prediction_test = model.transform(numericTest)\n",
    "Final_prediction_test = raw_prediction_test.select(\"MeaningfulWords\", \"prediction\")\n",
    "label_mapping_test= { \"0.0\": \"negative\", \"1.0\": \"neutral\", \"2.0\": \"positive\"}\n",
    "\n",
    "final_pred = Final_prediction_test.withColumn(\"prediction\", \n",
    "                          when(col(\"prediction\") == \"0.0\", label_mapping_test[\"0.0\"])\n",
    "                          .when(col(\"prediction\") == \"1.0\", label_mapping_test[\"1.0\"])\n",
    "                          .when(col(\"prediction\") == \"2.0\", label_mapping_test[\"2.0\"]))\n",
    "\n",
    "final_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1f05e-315e-4bfd-b956-8394f4ff2a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pywebio.input import *\n",
    "from pywebio.output import *\n",
    "from pywebio.session import run_js\n",
    "\n",
    "\n",
    "\n",
    "def SentimentAnalysis(input_sentence):\n",
    "    data = [(0, input_sentence)]\n",
    "    df = spark.createDataFrame(data, [\"id\", \"text\"])\n",
    "\n",
    "    tokenizedTest = tokenizer.transform(df)\n",
    "    SwRemovedTest = swr.transform(tokenizedTest)\n",
    "    numericTest = hashTF.transform(SwRemovedTest)\n",
    "    raw_prediction_test = model.transform(numericTest)\n",
    "    Final_prediction_test = raw_prediction_test.select(\"MeaningfulWords\", \"prediction\")\n",
    "    label_mapping_test= { \"0.0\": \"Negative\", \"1.0\": \"Neutral\", \"2.0\": \"Positive\"}\n",
    "    final_pred = Final_prediction_test.withColumn(\"prediction\", \n",
    "                          when(col(\"prediction\") == \"0.0\", label_mapping_test[\"0.0\"])\n",
    "                          .when(col(\"prediction\") == \"1.0\", label_mapping_test[\"1.0\"])\n",
    "                          .when(col(\"prediction\") == \"2.0\", label_mapping_test[\"2.0\"]))\n",
    "    \n",
    "    final_value = final_pred.select(\"prediction\").first()[0]\n",
    "\n",
    "    return final_value\n",
    "    \n",
    "\n",
    "def main():\n",
    "    put_button(\"ReUpload_images\",onclick=lambda: run_js('window.location.reload()'))\n",
    "    while True:\n",
    "        input_sentence = input(\"Please Input Sentence：\", type = 'text')\n",
    "        final_value = SentimentAnalysis(input_sentence)\n",
    "        if final_value=='Positive':\n",
    "            put_table([\n",
    "                ['Your sentence:', input_sentence],\n",
    "                ['Sentiment analysis result:', final_value]\n",
    "            ]).style('color: green; font-size: 24px')\n",
    "        elif final_value == 'Negative':\n",
    "            put_table([\n",
    "                ['Your sentence:', input_sentence],\n",
    "                ['Sentiment analysis result:', final_value]\n",
    "            ]).style('color: red; font-size: 24px')\n",
    "        else:\n",
    "            put_table([\n",
    "                ['Your sentence:', input_sentence],\n",
    "                ['Sentiment analysis result:', final_value]\n",
    "            ]).style('color: gray; font-size: 24px')\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f758d-3a05-44e6-9e11-793aa4d9bd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
